{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Categorical-Feature-Engineering-\" data-toc-modified-id=\"Categorical-Feature-Engineering--1\">Categorical Feature Engineering </a></span></li><li><span><a href=\"#Learning-Outcomes\" data-toc-modified-id=\"Learning-Outcomes-2\">Learning Outcomes</a></span></li><li><span><a href=\"#Categorical-Feature-Engineering-\" data-toc-modified-id=\"Categorical-Feature-Engineering--3\">Categorical Feature Engineering </a></span></li><li><span><a href=\"#What-are-the-methods-to-encode-categorical-features?\" data-toc-modified-id=\"What-are-the-methods-to-encode-categorical-features?-4\">What are the methods to encode categorical features?</a></span></li><li><span><a href=\"#What-is-the-difference-between-pd.get_dummies-and-sklearn.preprocessing.OneHotEncoder?\" data-toc-modified-id=\"What-is-the-difference-between-pd.get_dummies-and-sklearn.preprocessing.OneHotEncoder?-5\">What is the difference between pd.get_dummies and sklearn.preprocessing.OneHotEncoder?</a></span></li><li><span><a href=\"#What-is-Hashing?\" data-toc-modified-id=\"What-is-Hashing?-6\">What is Hashing?</a></span></li><li><span><a href=\"#What-are-Hash-Maps?\" data-toc-modified-id=\"What-are-Hash-Maps?-7\">What are Hash Maps?</a></span></li><li><span><a href=\"#Feature-Hashing,-aka-hashing-trick\" data-toc-modified-id=\"Feature-Hashing,-aka-hashing-trick-8\">Feature Hashing, aka hashing trick</a></span></li><li><span><a href=\"#The-Advantages-of-Feature-Hashing\" data-toc-modified-id=\"The-Advantages-of-Feature-Hashing-9\">The Advantages of Feature Hashing</a></span></li><li><span><a href=\"#The-Disadvantages-of-Feature-Hashing\" data-toc-modified-id=\"The-Disadvantages-of-Feature-Hashing-10\">The Disadvantages of Feature Hashing</a></span></li><li><span><a href=\"#Embeddings-(e.g.,-word2vec)\" data-toc-modified-id=\"Embeddings-(e.g.,-word2vec)-11\">Embeddings (e.g., word2vec)</a></span></li><li><span><a href=\"#How-to-use-word-embeddings-in-a-ML-Algorithm\" data-toc-modified-id=\"How-to-use-word-embeddings-in-a-ML-Algorithm-12\">How to use word embeddings in a ML Algorithm</a></span></li><li><span><a href=\"#StarSpace-Package:-Embed-All-The-Things!\" data-toc-modified-id=\"StarSpace-Package:-Embed-All-The-Things!-13\">StarSpace Package: Embed All The Things!</a></span></li><li><span><a href=\"#How-to-use-StarSpace-embeddings-in-a-ML-Algorithm\" data-toc-modified-id=\"How-to-use-StarSpace-embeddings-in-a-ML-Algorithm-14\">How to use StarSpace embeddings in a ML Algorithm</a></span></li><li><span><a href=\"#Comparing-Encoding-Methods\" data-toc-modified-id=\"Comparing-Encoding-Methods-15\">Comparing Encoding Methods</a></span></li><li><span><a href=\"#Takeaways\" data-toc-modified-id=\"Takeaways-16\">Takeaways</a></span></li><li><span><a href=\"#Bonus-Material\" data-toc-modified-id=\"Bonus-Material-17\">Bonus Material</a></span></li><li><span><a href=\"#Bin-Counting\" data-toc-modified-id=\"Bin-Counting-18\">Bin Counting</a></span></li><li><span><a href=\"#Bin-Counting\" data-toc-modified-id=\"Bin-Counting-19\">Bin Counting</a></span></li><li><span><a href=\"#Check-for-understanding\" data-toc-modified-id=\"Check-for-understanding-20\">Check for understanding</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Categorical Feature Engineering </h2></center>\n",
    "\n",
    "<center><img src=\"images/0_iKsDex5fUBQoYTju.png\" width=\"100%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Learning Outcomes</h2></center>\n",
    "\n",
    "__By the end of this session, you should be able to__:\n",
    "\n",
    "- List the common methods of encoding categorical features.\n",
    "- Compare and contrast the common methods of encoding categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Categorical Feature Engineering </h2></center>\n",
    "\n",
    "Categorical variables needs to be transformed into numbers that amendable to machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Examples of categorical variables: Products, users, words, â€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What are the methods to encode categorical features?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- One-Hot Encoding / Dummy Encoding\n",
    "- Label Encoding\n",
    "- Feature Hashing\n",
    "- Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What is the difference between pd.get_dummies and sklearn.preprocessing.OneHotEncoder?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`pd.get_dummies` creates a DataFrame to manage encoded variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`sklearn.preprocessing.OneHotEncoder` creates an OneHotEncoder object to manage encoded variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(['Positive', 'Positive', 'Negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Negative  Positive\n",
       "0         0         1\n",
       "1         0         1\n",
       "2         1         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.get_dummies(pd.Series(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_Negative', 'x0_Positive'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(X.reshape(-1, 1))\n",
    "enc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(X.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine fit and transform\n",
    "enc.fit_transform(X.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>What is Hashing?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Converting an object into a single numeric value.</center>\n",
    "\n",
    "<center> Map data of arbitrary sizes to data of a fixed size.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><h2>What are Hash Maps?</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>Key-value pairs - where the key is numeric location (index) and the value is an object</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Feature Hashing, aka hashing trick</h2></center>\n",
    "<br>\n",
    "<center><img src=\"images/feature_hashing.jpeg\" width=\"100%\"/></center>\n",
    "\n",
    "<center>Map feature values to indices in a feature vector.</center>\n",
    "\n",
    "<center>Those feature values could be <b>any</b> hashable object</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://www.quora.com/Can-you-explain-feature-hashing-in-an-easily-understandable-way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "FeatureHasher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-16., -50.,  25.,  21.,  11., -15.,  -3.,  -2.,   0., -30.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's feature hash \n",
    "h = FeatureHasher(n_features=10)\n",
    "# d = [{'dog': 10,}] # 1 instance & 1 feature with a value\n",
    "# d = [{'dog': 4,}] # 1 instance & 1 feature with a changed value\n",
    "# d = [{'dog': 10, 'cat':2, 'elephant':4}] # 1 instance & 3 features\n",
    "# d = [{'dog': 10, 'cat':2, 'elephant':4}, # 2 instances\n",
    "#      {'dog': 2, 'run': 5}] \n",
    "d = [{l:n for l, n in zip('abcdefghijklmnopqrstuvwxyz', range(26))}] # 1 instance & many features ðŸ¤­\n",
    "    \n",
    "h.transform(d).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Learn more: https://www.youtube.com/watch?v=Uv9dY6Obv-s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>The Advantages of Feature Hashing</h2></center>\n",
    "\n",
    "- Fast \n",
    "- Simple\n",
    "- Memory efficient\n",
    "    - Limits feature vector size (compared to one-hot encoding)\n",
    "    - No need to store mapping feature itself (just index integer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>The Disadvantages of Feature Hashing</h2></center>\n",
    "\n",
    "- Interpretability & feature importances - Cannot go from feature indices back to feature names\n",
    "- Hash collisions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Embeddings (e.g., word2vec)</h2></center>\n",
    "\n",
    "<center><img src=\"images/0_A9qy9wS7m-eMKiX6.png\" width=\"45%\"/></center>\n",
    "\n",
    "<center>Project sparse high-dimensional categorical data into a dense, low-dimensional numeric vector.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: https://instagram-engineering.com/emojineering-part-1-machine-learning-for-emoji-trendsmachine-learning-for-emoji-trends-7f5f9cb979ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to use word embeddings in a ML Algorithm</h2></center>\n",
    "\n",
    "1. Train (or download) word embeddings.\n",
    "1. Create a document embedding by taking the an average of words vectors for that document.\n",
    "1. Each dimension is a feature.\n",
    "1. Train the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For example, tree-based classifier would learn which parts of the embedding space are associated with a specific label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>StarSpace Package: Embed All The Things!</h2></center>\n",
    "\n",
    "<center><img src=\"images/product_embedding.png\" width=\"75%\"/></center>\n",
    "\n",
    "Embedded any sequential discrete data. \n",
    "\n",
    "Examples: Words, emojis, documents, products, images, videos, â€¦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>How to use StarSpace embeddings in a ML Algorithm</h2></center>\n",
    "\n",
    "1. Train (or download) embeddings where every entity is embedded into the same space.\n",
    "1. Each dimension is a feature.\n",
    "1. Train the machine learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Source: \n",
    "\n",
    "- https://research.fb.com/downloads/starspace/\n",
    "- https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
       "     font-size: 100%;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".rendered_html table, .rendered_html th, .rendered_html tr, .rendered_html td {\n",
    "     font-size: 100%;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Comparing Encoding Methods</h2></center>\n",
    "\n",
    "| Method | Size Requirements |  Growth |\n",
    "|:-------:|:------:|:------:|\n",
    "| One-Hot Encoding | Cardinality of data| Unbounded |\n",
    "| Feature Hashing | Hash table size | Fixed | \n",
    "| Embeddings | Feature space dimensions | Fixed | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><h2>Takeaways</h2></center>\n",
    "\n",
    "- One-hot encoding works well for small number of categories\n",
    "- Features hashing works well for medium number of categories.\n",
    "- Embeddings are the best choice (if possible).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bonus Material\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bin Counting\n",
    "-------\n",
    "\n",
    "<center><img src=\"images/counts.png\" width=\"75%\"/></center>\n",
    "\n",
    "Rather than using the value of the categorical variable as the feature, instead use the __conditional probability of the target under that value__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bin Counting\n",
    "-----\n",
    "\n",
    "<center><img src=\"images/bin_conts.png\" width=\"75%\"/></center>\n",
    "\n",
    "Use probability of click as a feature (not just raw click or not click).\n",
    "\n",
    "Turns a large, sparse, binary representation of the categorical variable (e.g., one-hot encoding) into a very small, dense, real-valued numeric representation\n",
    "\n",
    "Bin Counting: _m_ bin table size, fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Check for understanding\n",
    "-----\n",
    "\n",
    "What is the difference between Bin Counting and Naive Bayes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Naive Bayes always multiplies the conditional probabilities.\n",
    "\n",
    "Bin counting treat them as features, which can be used in other models such as trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Learn more:\n",
    "- https://blogs.technet.microsoft.com/machinelearning/2015/02/17/big-learning-made-easy-with-counts/\n",
    "- https://www.slideshare.net/SessionsEvents/misha-bilenko-principal-researcher-microsoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
